# Hand Gesture Recognition for Sign Language Letter Classification
### Overview
This project focuses on hand gesture recognition for sign language letter classification using various deep learning models. The goal is to accurately classify hand gestures representing different letters of the sign language alphabet.

The following deep learning models were trained and evaluated for this task:

<b>Basic CNN Model:</b> Achieved an accuracy of <b>94.15%</b> on the training datase and <b>96.60%</b> on validation dataset.

<b>VGG16 Transfer Learning:</b> Achieved an accuracy of <b>99.53%</b> on the training dataset and <b>99.20%</b> on validation dataset.

<b>DenseNet121:</b> Achieved an accuracy of <b>97.84%</b> on the training dataset and <b>97.17%</b> on validation dataset.

<b>VGG16 Fine-tuning:</b> Achieved an accuracy of <b>97.78%</b> on the training dataset and <b>97.44%</b> on validation dataset.

Additionally, confusion matrices were calculated for each model to evaluate the classification performance across different classes.
